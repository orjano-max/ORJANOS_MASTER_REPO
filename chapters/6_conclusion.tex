\chapter{Conclusions}
The main goal of this thesis has been to modify an existing autonomous mobile robotic system in order to give it capabilities to preform warehouse automation tasks. Additionally, the system should be modular and easy to adapt for future students and researchers. To validate the solution, a warehouse automation scenario has been defined as a benchmark task that the system should be able to perform. 

The solution can be divided into three main categories, autonomous navigation, pick and place, and top-level. Autonomous navigation is tasked with providing robust mobile robot navigation in a warehouse environment. Pick and place is tasked with giving robust pick and place operations including computer vision-based object detection and pose estimation for picking. Top-level is tasked with orchestrating the two other parts of the solutions in order to complete the benchmark task described by the test scenario.

Although the existing mobile robot had autonomous navigation capabilities, modifications have been made to the system in order to accommodate other systems. These changes include addition of an accessory mounting frame, and merging of navigational algorithms to another Robot Operating System 2 (ROS 2) distribution. Additionally, more sensor information in the form of Inertial Measurement Unit (IMU) data is passed to the system in order to help improve performance. Nevertheless, the performance of the navigational system suffers from an inherently inaccurate locomotion mechanism in the mobile robot provided for this thesis. Sharp turns have the possibility of completely confusing the entire autonomous navigation system. The extra IMU data might have helped with this issue, but the positive effects of this modification are uncertain.

The Pick and place solution consists of a robotic manipulator, a computer vision system and ROS 2 packages developed during this project. The computer vision system is based on fiducial tag-detection using AprilTag. The chosen manipulator is a 5-degrees of freedom (DOF) manipulator by Interbotix called VX300. In order to interface the manipulator with the top-level system, a ROS 2 package that listens for simple commands, moves the manipulator based on them, and provides simple operational feedback was developed. Additionally, a ROS 2 package that encapsulates the mobile robot in collision objects, to avoid manipulator colliding with the mobile robot is made.

The fiducial tag-based computer vision system proved to give seemingly robust object detection and repeatable pose estimation, but poorly defined vision camera placement (external calibration) seemed to result in poor pose definition. No measurements were made to verify it's accuracy or repeatability. The chosen robotic manipulator gave poor performance in terms of working payload and reach. Measurements in pick and place accuracy were not made, as the computer vision system would need more adjustments. However, the manipulator was able to pick detected objects if the reported pose estimation was accurate enough.

The top-level system was tested on a physical test setup of the system, a simulated test setup of the system as well as a simulation of a TurtleBot3, which is a popular mobile robot for development and educational use. In all tests, the system was able to orchestrate the defined warehouse automation scenario. For the first two tests, some changes to the goal-pose commands sent to the navigation system was made in order to overcome issues related to navigation and limited manipulator reach. Other than this, the top-level system proved to work with various mobile robotic systems without modifications. It is worth noticing that the top-level system is more specific in terms of manipulator.

Overall, it can be concluded that this project was successful at retrofitting the provided mobile robotic system to be able to perform warehouse automation tasks. Although the solution lacks robustness, accuracy and flexibility, the solution can be seen as a proof of concept that can be further improved with future works.

